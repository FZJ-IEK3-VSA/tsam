{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Determine the optimal combination of segments and periods for time series aggregation.\n",
    "\n",
    "Author: Leander Kotzur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "import tsam\n",
    "from tsam import ClusterConfig\n",
    "from tsam.tuning import find_pareto_front\n",
    "\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data\n",
    "\n",
    "Read in time series from testdata.csv with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"testdata.csv\", index_col=0)\n",
    "raw = raw.rename(\n",
    "    columns={\"T\": \"Temperature\", \"Load\": \"Demand\", \"Wind\": \"Wind\", \"GHI\": \"Solar\"}\n",
    ")\n",
    "period_hours = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsam.plot.heatmaps(raw, period_hours=period_hours, title=\"Original Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Pareto-optimal aggregations\n",
    "\n",
    "Use `find_pareto_front()` to explore the Pareto-optimal combinations of periods and segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_results = find_pareto_front(\n",
    "    raw,\n",
    "    period_hours=period_hours,\n",
    "    max_timesteps=100,  # Limit for faster demo (use 8760 for full exploration)\n",
    "    cluster=ClusterConfig(method=\"hierarchical\", representation=\"duration\"),\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_result = pareto_results[-1]\n",
    "print(\n",
    "    f\"Final: {last_result.optimal_n_periods} periods, {last_result.optimal_n_segments} segments, RMSE: {last_result.optimal_rmse:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = last_result.best_result.reconstruct()\n",
    "tsam.plot.heatmaps(\n",
    "    reconstructed,\n",
    "    reference_data=raw,\n",
    "    period_hours=period_hours,\n",
    "    title=\"Reconstructed Data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animated visualization\n",
    "\n",
    "Animate through all Pareto-optimal aggregations to visualize the trade-off between compression and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = len(raw) // period_hours\n",
    "n_vars = len(raw.columns)\n",
    "\n",
    "# Build 4D array: (frames, variables, hours, days)\n",
    "frames_data, labels = [], []\n",
    "for result in reversed(pareto_results):\n",
    "    p, s = result.optimal_n_periods, result.optimal_n_segments\n",
    "    labels.append(f\"{round((1 - s * p / len(raw)) * 100, 1)}% ({p}p x {s}s)\")\n",
    "\n",
    "    # Reshape to (n_vars, period_hours, n_days)\n",
    "    data = (\n",
    "        result.best_result.reconstruct().values.reshape(n_days, period_hours, n_vars).T\n",
    "    )\n",
    "    frames_data.append(data)\n",
    "\n",
    "img_stack = np.stack(frames_data)  # Shape: (frames, vars, hours, days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(\n",
    "    img_stack,\n",
    "    animation_frame=0,\n",
    "    facet_col=1,\n",
    "    color_continuous_scale=\"RdYlBu_r\",\n",
    "    aspect=\"auto\",\n",
    "    labels={\"x\": \"Day\", \"y\": \"Hour\", \"facet_col\": \"Variable\"},\n",
    "    title=\"Time Series Aggregation\",\n",
    ")\n",
    "\n",
    "# Update slider labels\n",
    "for i, step in enumerate(fig.layout.sliders[0].steps):\n",
    "    step[\"label\"] = labels[i]\n",
    "\n",
    "# Update facet titles with variable names\n",
    "fig.for_each_annotation(\n",
    "    lambda a: a.update(text=raw.columns[int(a.text.split(\"=\")[-1])])\n",
    ")\n",
    "fig.update_layout(height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"segments\": r.optimal_n_segments,\n",
    "            \"periods\": r.optimal_n_periods,\n",
    "            \"rmse\": r.optimal_rmse,\n",
    "        }\n",
    "        for r in pareto_results\n",
    "    ]\n",
    ")\n",
    "pareto_df.to_csv(os.path.join(\"results\", \"paretoOptimalAggregation.csv\"))\n",
    "fig.write_html(os.path.join(\"results\", \"animation.html\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
