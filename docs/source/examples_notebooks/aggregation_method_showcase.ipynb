{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tsam - Clustering Methods Showcase\n",
    "\n",
    "This notebook demonstrates all clustering methods and configuration options available in tsam.\n",
    "\n",
    "## Available Methods\n",
    "\n",
    "| Method | Description | Best For |\n",
    "|--------|-------------|----------|\n",
    "| `hierarchical` | Agglomerative hierarchical clustering | General purpose, recommended default |\n",
    "| `kmeans` | K-means with centroids | Fast clustering, large datasets |\n",
    "| `kmedoids` | K-medoids (MILP exact) | Optimal solution, smaller datasets (slow) |\n",
    "| `kmaxoids` | Selects most dissimilar periods | Capturing extremes |\n",
    "| `contiguous` | Hierarchical with temporal constraint | Storage modeling, seasonal patterns |\n",
    "| `averaging` | Sequential period averaging | Simple baseline |\n",
    "\n",
    "**Tip:** For medoid-based clustering on large datasets, use `hierarchical` with `representation=\"medoid\"` instead of `kmedoids`.\n",
    "\n",
    "## Key Configuration Options\n",
    "\n",
    "| Option | Description |\n",
    "|--------|-------------|\n",
    "| `weights` | Per-column importance weights |\n",
    "| `representation` | How to represent cluster centers (mean, medoid, maxoid, distribution, distribution_minmax) |\n",
    "| `normalize_column_means` | Normalize columns to same mean before clustering |\n",
    "| `use_duration_curves` | Match by value distribution rather than timing |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "import tsam\n",
    "from tsam import ClusterConfig\n",
    "\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset contains hourly time series for one year with four columns:\n",
    "- **GHI**: Global Horizontal Irradiance (solar)\n",
    "- **T**: Temperature\n",
    "- **Wind**: Wind speed\n",
    "- **Load**: Electrical load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"testdata.csv\", index_col=0)\n",
    "print(f\"Shape: {raw.shape} ({raw.shape[0]} hours = {raw.shape[0] // 24} days)\")\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hierarchical Clustering (Recommended Default)\n",
    "\n",
    "Agglomerative hierarchical clustering builds a tree of clusters and cuts it at the desired number. It's the recommended default because it:\n",
    "- Produces consistent results (deterministic)\n",
    "- Works well with various representations\n",
    "- Handles multi-variate data effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_hierarchical = tsam.aggregate(\n",
    "    raw,\n",
    "    n_clusters=8,\n",
    "    period_duration=24,\n",
    "    cluster=ClusterConfig(method=\"hierarchical\"),\n",
    ")\n",
    "print(f\"Accuracy: RMSE = {result_hierarchical.accuracy.rmse.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering\n",
    "\n",
    "K-means is fast and widely used. It computes cluster centroids (averages), which may not correspond to actual periods in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_kmeans = tsam.aggregate(\n",
    "    raw,\n",
    "    n_clusters=8,\n",
    "    period_duration=24,\n",
    "    cluster=ClusterConfig(method=\"kmeans\"),\n",
    ")\n",
    "print(f\"Accuracy: RMSE = {result_kmeans.accuracy.rmse.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Medoids-like Clustering\n",
    "\n",
    "K-medoids selects actual periods as cluster centers (medoids) rather than computing averages. This preserves realistic patterns.\n",
    "\n",
    "**Note:** The true `kmedoids` method uses an exact MILP solver which can be slow for large datasets. For most use cases, `hierarchical` with `representation=\"medoid\"` gives similar results much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hierarchical with medoid representation (fast alternative to kmedoids)\n",
    "result_kmedoids = tsam.aggregate(\n",
    "    raw,\n",
    "    n_clusters=8,\n",
    "    period_duration=24,\n",
    "    cluster=ClusterConfig(method=\"hierarchical\", representation=\"medoid\"),\n",
    ")\n",
    "print(f\"Accuracy: RMSE = {result_kmedoids.accuracy.rmse.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Maxoids Clustering\n",
    "\n",
    "K-maxoids selects the most dissimilar periods as cluster centers. This is useful for capturing extreme conditions.\n",
    "\n",
    "**Note:** We set `preserve_column_means=False` below because mean preservation adjusts typical period values to match the original data's mean. For k-maxoids, where the goal is to preserve extreme values, this would diminish the very extremes we're trying to capture. Use `preserve_column_means=True` (default) when mean preservation is more important than extreme value preservation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_kmaxoids = tsam.aggregate(\n",
    "    raw,\n",
    "    n_clusters=8,\n",
    "    period_duration=24,\n",
    "    cluster=ClusterConfig(method=\"kmaxoids\"),\n",
    "    preserve_column_means=False,  # Don't rescale to preserve extreme values\n",
    ")\n",
    "print(f\"Accuracy: RMSE = {result_kmaxoids.accuracy.rmse.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Contiguous Clustering\n",
    "\n",
    "Contiguous clustering enforces temporal continuity - adjacent typical periods must come from adjacent original periods. This is important for:\n",
    "- **Storage modeling**: State-of-charge must be continuous\n",
    "- **Seasonal patterns**: Preserving the natural progression of seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_contiguous = tsam.aggregate(\n",
    "    raw,\n",
    "    n_clusters=8,\n",
    "    period_duration=24,\n",
    "    cluster=ClusterConfig(method=\"contiguous\"),\n",
    ")\n",
    "print(f\"Accuracy: RMSE = {result_contiguous.accuracy.rmse.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison of Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results for comparison\n",
    "results = {\n",
    "    \"Original\": raw,\n",
    "    \"Hierarchical\": result_hierarchical.reconstructed,\n",
    "    \"K-Means\": result_kmeans.reconstructed,\n",
    "    \"K-Medoids\": result_kmedoids.reconstructed,\n",
    "    \"K-Maxoids\": result_kmaxoids.reconstructed,\n",
    "    \"Contiguous\": result_contiguous.reconstructed,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration Curve Comparison\n",
    "\n",
    "Duration curves show how well each method preserves the value distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration curve comparison - Load\n",
    "frames = []\n",
    "for name, df in results.items():\n",
    "    sorted_vals = df[\"Load\"].sort_values(ascending=False).reset_index(drop=True)\n",
    "    frames.append(\n",
    "        pd.DataFrame(\n",
    "            {\"Hour\": range(len(sorted_vals)), \"Load\": sorted_vals, \"Method\": name}\n",
    "        )\n",
    "    )\n",
    "long_df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "px.line(\n",
    "    long_df,\n",
    "    x=\"Hour\",\n",
    "    y=\"Load\",\n",
    "    color=\"Method\",\n",
    "    title=\"Duration Curve Comparison - Load\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration curve comparison - GHI\n",
    "frames = []\n",
    "for name, df in results.items():\n",
    "    sorted_vals = df[\"GHI\"].sort_values(ascending=False).reset_index(drop=True)\n",
    "    frames.append(\n",
    "        pd.DataFrame(\n",
    "            {\"Hour\": range(len(sorted_vals)), \"GHI\": sorted_vals, \"Method\": name}\n",
    "        )\n",
    "    )\n",
    "long_df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "px.line(\n",
    "    long_df, x=\"Hour\", y=\"GHI\", color=\"Method\", title=\"Duration Curve Comparison - GHI\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare RMSE across methods\n",
    "accuracy_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"Method\": [\"Hierarchical\", \"K-Means\", \"K-Medoids\", \"K-Maxoids\", \"Contiguous\"],\n",
    "        \"Mean RMSE\": [\n",
    "            result_hierarchical.accuracy.rmse.mean(),\n",
    "            result_kmeans.accuracy.rmse.mean(),\n",
    "            result_kmedoids.accuracy.rmse.mean(),\n",
    "            result_kmaxoids.accuracy.rmse.mean(),\n",
    "            result_contiguous.accuracy.rmse.mean(),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "accuracy_comparison.sort_values(\"Mean RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Configuration Options\n",
    "\n",
    "### Using Weights\n",
    "\n",
    "When clustering multi-variate time series, you can assign different importance to each column. This is useful when one variable is more critical for your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prioritize Load over other columns (e.g., for demand-focused energy systems)\n",
    "result_weighted = tsam.aggregate(\n",
    "    raw,\n",
    "    n_clusters=8,\n",
    "    period_duration=24,\n",
    "    cluster=ClusterConfig(\n",
    "        method=\"hierarchical\",\n",
    "        weights={\"Load\": 3.0, \"GHI\": 1.0, \"T\": 1.0, \"Wind\": 1.0},\n",
    "    ),\n",
    ")\n",
    "print(f\"Load RMSE (weighted): {result_weighted.accuracy.rmse['Load']:.4f}\")\n",
    "print(f\"Load RMSE (unweighted): {result_hierarchical.accuracy.rmse['Load']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Duration Curves for Clustering\n",
    "\n",
    "By default, clustering matches periods by their temporal patterns. Setting `use_duration_curves=True` matches periods by their value distributions instead, ignoring timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster by value distribution rather than temporal pattern\n",
    "result_duration_curves = tsam.aggregate(\n",
    "    raw,\n",
    "    n_clusters=8,\n",
    "    period_duration=24,\n",
    "    cluster=ClusterConfig(\n",
    "        method=\"hierarchical\",\n",
    "        use_duration_curves=True,\n",
    "    ),\n",
    ")\n",
    "print(f\"RMSE with duration curves: {result_duration_curves.accuracy.rmse.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution-Preserving Representation\n",
    "\n",
    "The `distribution_minmax` representation preserves both the value distribution AND the min/max values. This is excellent for energy system optimization where both the shape and extremes matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use distribution_minmax representation\n",
    "result_dist_minmax = tsam.aggregate(\n",
    "    raw,\n",
    "    n_clusters=8,\n",
    "    period_duration=24,\n",
    "    cluster=ClusterConfig(\n",
    "        method=\"hierarchical\",\n",
    "        representation=\"distribution_minmax\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Compare min/max preservation\n",
    "print(\"Original data range:\")\n",
    "print(f\"  Load: {raw['Load'].min():.2f} - {raw['Load'].max():.2f}\")\n",
    "\n",
    "reconstructed_standard = result_hierarchical.reconstructed\n",
    "reconstructed_dist = result_dist_minmax.reconstructed\n",
    "\n",
    "print(\"\\nStandard medoid representation:\")\n",
    "print(\n",
    "    f\"  Load: {reconstructed_standard['Load'].min():.2f} - {reconstructed_standard['Load'].max():.2f}\"\n",
    ")\n",
    "\n",
    "print(\"\\nDistribution + MinMax representation:\")\n",
    "print(\n",
    "    f\"  Load: {reconstructed_dist['Load'].min():.2f} - {reconstructed_dist['Load'].max():.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: Standard vs Distribution-Preserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison: Standard vs Distribution-Preserving\n",
    "comparison_dist = {\n",
    "    \"Original\": raw,\n",
    "    \"Medoid (standard)\": reconstructed_standard,\n",
    "    \"Distribution + MinMax\": reconstructed_dist,\n",
    "}\n",
    "\n",
    "frames = []\n",
    "for name, df in comparison_dist.items():\n",
    "    sorted_vals = df[\"Load\"].sort_values(ascending=False).reset_index(drop=True)\n",
    "    frames.append(\n",
    "        pd.DataFrame(\n",
    "            {\"Hour\": range(len(sorted_vals)), \"Load\": sorted_vals, \"Method\": name}\n",
    "        )\n",
    "    )\n",
    "long_df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "px.line(\n",
    "    long_df,\n",
    "    x=\"Hour\",\n",
    "    y=\"Load\",\n",
    "    color=\"Method\",\n",
    "    title=\"Effect of Distribution-Preserving Representation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Use Case | Recommended Method | Key Options |\n",
    "|----------|-------------------|-------------|\n",
    "| General purpose | `hierarchical` | Default settings |\n",
    "| Fast clustering | `kmeans` | - |\n",
    "| Preserve realistic patterns | `hierarchical` | `representation=\"medoid\"` |\n",
    "| Capture extremes | `kmaxoids` | `preserve_column_means=False` |\n",
    "| Storage modeling | `contiguous` | - |\n",
    "| Demand-focused | `hierarchical` | `weights={\"Load\": 3.0, ...}` |\n",
    "| Preserve distribution | `hierarchical` | `representation=\"distribution_minmax\"` |\n",
    "\n",
    "**Note:** The `kmedoids` method uses an exact MILP solver and can be slow for datasets with many periods (365+ days). Use `hierarchical` with `representation=\"medoid\"` for similar results with much better performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
