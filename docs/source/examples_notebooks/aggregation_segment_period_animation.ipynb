{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tsam - Animation of pareto-optimal aggregation\n",
    "Date: 02.05.2022\n",
    "\n",
    "Author: Leander Kotzur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas and the relevant time series aggregation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import tsam.hyperparametertuning as tune\n",
    "from tsam.timeseriesaggregation import TimeSeriesAggregation, unstackToPeriods\n",
    "\n",
    "%matplotlib inline\n",
    "import math\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams[\"animation.embed_limit\"] = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in time series from testdata.csv with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"testdata.csv\", index_col=0)\n",
    "raw = raw.rename(\n",
    "    columns={\n",
    "        \"T\": \"Temperature [°C]\",\n",
    "        \"Load\": \"Demand [kW]\",\n",
    "        \"Wind\": \"Wind [m/s]\",\n",
    "        \"GHI\": \"Solar [W/m²]\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the hyperparameter instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunedAggregations = tune.HyperTunedAggregations(\n",
    "    TimeSeriesAggregation(\n",
    "        raw,\n",
    "        hoursPerPeriod=24,\n",
    "        clusterMethod=\"hierarchical\",\n",
    "        representationMethod=\"medoidRepresentation\",\n",
    "        rescaleClusterPeriods=False,\n",
    "        segmentation=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the resulting combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\n",
    "    os.path.join(\"results\", \"paretoOptimalAggregation.csv\"), index_col=0\n",
    ")\n",
    "results[\"time_steps\"] = results[\"segments\"] * results[\"periods\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the animated aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all results with timesteps below 1% of the original data set since they are not meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[results[\"time_steps\"] > 80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the original time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat(\n",
    "    [results, pd.DataFrame([{\"segments\": 24, \"periods\": 365, \"time_steps\": len(raw)}])],\n",
    "    ignore_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And reverse the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.iloc[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create a dictionary with all aggregations we want to show in the animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "animation_list = []\n",
    "previouspredictedPeriods = None\n",
    "for i, index in enumerate(tqdm.tqdm(results.index)):\n",
    "    segments = results.loc[index, :].to_dict()[\"segments\"]\n",
    "    periods = results.loc[index, :].to_dict()[\"periods\"]\n",
    "    # aggregate to the selected set\n",
    "    tunedAggregations._testAggregation(noTypicalPeriods=periods, noSegments=segments)\n",
    "    # and repredict the data\n",
    "    prediction = tunedAggregations.aggregationHistory[-1].predictOriginalData()\n",
    "    # relative reduction of time steps\n",
    "    reduction = 1 - (\n",
    "        float(\n",
    "            tunedAggregations._segmentHistory[-1] * tunedAggregations._periodHistory[-1]\n",
    "        )\n",
    "        / len(raw)\n",
    "    )\n",
    "\n",
    "    # add a change layer which shows the difference of the latest aggregation to the previous\n",
    "    if i > 0:\n",
    "        # difference\n",
    "        diff_val = previouspredictedPeriods - prediction\n",
    "        # all fields that changed\n",
    "        diff_bool = abs(diff_val) > 1e-10\n",
    "        # make sure that when any change is there it gets set to Nan\n",
    "        prediction_diff = copy.deepcopy(prediction)\n",
    "        prediction_diff[diff_bool.max(axis=1)] = np.nan\n",
    "\n",
    "        # what changes ? segments or periods\n",
    "        if segments == animation_list[-1][\"Segments\"]:\n",
    "            misc = \"Clustering periods\"\n",
    "        else:\n",
    "            misc = \"Clustering segments\"\n",
    "\n",
    "        animation_list.append(\n",
    "            {\n",
    "                \"Prediction\": prediction_diff,\n",
    "                \"Segments\": segments,\n",
    "                \"Periods\": periods,\n",
    "                \"Reduction\": reduction,\n",
    "                \"Misc\": \"Medoid representation\",  # misc,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    animation_list.append(\n",
    "        {\n",
    "            \"Prediction\": prediction,\n",
    "            \"Segments\": segments,\n",
    "            \"Periods\": periods,\n",
    "            \"Reduction\": reduction,\n",
    "            \"Misc\": \"Medoid representation\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # and set previous prediction preiods\n",
    "    previouspredictedPeriods = prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then append a last aggregation with the novel duration/distribution represenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = TimeSeriesAggregation(\n",
    "    raw,\n",
    "    hoursPerPeriod=24,\n",
    "    noSegments=segments,\n",
    "    noTypicalPeriods=periods,\n",
    "    clusterMethod=\"hierarchical\",\n",
    "    rescaleClusterPeriods=False,\n",
    "    segmentation=True,\n",
    "    representationMethod=\"durationRepresentation\",\n",
    "    distributionPeriodWise=False,\n",
    ")\n",
    "\n",
    "animation_list.append(\n",
    "    {\n",
    "        \"Prediction\": aggregation.predictOriginalData(),\n",
    "        \"Segments\": segments,\n",
    "        \"Periods\": periods,\n",
    "        \"Reduction\": reduction,\n",
    "        \"Misc\": \"Distribution representation\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let animation warp - slow in the beginning and slow in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = []\n",
    "\n",
    "for i in range(len(animation_list)):\n",
    "    if i < 1:\n",
    "        iterator += [i] * 100\n",
    "    elif i < 3:\n",
    "        iterator += [i] * 50\n",
    "    elif i < 6:\n",
    "        iterator += [i] * 30\n",
    "    elif i < 20:\n",
    "        iterator += [i] * 10\n",
    "    elif i >= len(animation_list) - 1:\n",
    "        iterator += [i] * 150\n",
    "    elif i > len(animation_list) - 3:\n",
    "        iterator += [i] * 50\n",
    "    elif i > len(animation_list) - 6:\n",
    "        iterator += [i] * 30\n",
    "    else:\n",
    "        iterator += [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the plot and the animation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=[7, 5], dpi=300, nrows=raw.shape[1], ncols=1)\n",
    "cmap = plt.cm.get_cmap(\"Spectral_r\").copy()\n",
    "cmap.set_bad((0.7, 0.7, 0.7, 1))\n",
    "for ii, column in enumerate(raw.columns):\n",
    "    data = raw[column]\n",
    "    stacked, _timeindex = unstackToPeriods(\n",
    "        copy.deepcopy(data), tunedAggregations.base_aggregation.hoursPerPeriod\n",
    "    )\n",
    "    _cax = axes[ii].imshow(\n",
    "        stacked.values.T,\n",
    "        interpolation=\"nearest\",\n",
    "        vmin=raw[column].min(),\n",
    "        vmax=raw[column].max(),\n",
    "        origin=\"lower\",\n",
    "        cmap=cmap,\n",
    "    )\n",
    "    axes[ii].set_aspect(\"auto\")\n",
    "    axes[ii].set_ylabel(\"Hour\")\n",
    "    plt.xlabel(\"Day in the year\")\n",
    "    cbar = plt.colorbar(_cax, ax=axes[ii], pad=0.01, aspect=7)\n",
    "    cbar.set_label(column, fontsize=\"small\")\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Time series aggregation by xx.xx %\",\n",
    "    y=0.97,\n",
    "    x=0.3,\n",
    "    horizontalalignment=\"left\",\n",
    ")\n",
    "text = fig.text(\n",
    "    0.27,\n",
    "    0.91,\n",
    "    \"with xxx periods and xx segments - Medoid representation\",\n",
    "    horizontalalignment=\"left\",\n",
    "    fontsize=\"small\",\n",
    ")\n",
    "fig.subplots_adjust(right=1.1, hspace=0.05)\n",
    "\n",
    "\n",
    "def animate(iter):\n",
    "    i = iterator[iter]\n",
    "    predictedPeriods = animation_list[i][\"Prediction\"]\n",
    "    fig.suptitle(\n",
    "        \"Time series aggregation by \"\n",
    "        + str(round(animation_list[i][\"Reduction\"] * 100, 2))\n",
    "        + \" % \",\n",
    "        y=0.97,\n",
    "        x=0.3,\n",
    "        horizontalalignment=\"left\",\n",
    "    )\n",
    "    text.set_text(\n",
    "        \"with \"\n",
    "        + str(animation_list[i][\"Periods\"])\n",
    "        + \" periods and \"\n",
    "        + str(animation_list[i][\"Segments\"])\n",
    "        + \" segments - \"\n",
    "        + animation_list[i][\"Misc\"],\n",
    "    )\n",
    "    for ii, column in enumerate(raw.columns):\n",
    "        data = predictedPeriods[column]\n",
    "        stacked, _timeindex = unstackToPeriods(\n",
    "            copy.deepcopy(data), tunedAggregations.base_aggregation.hoursPerPeriod\n",
    "        )\n",
    "        _cax = axes[ii].imshow(\n",
    "            stacked.values.T,\n",
    "            interpolation=\"nearest\",\n",
    "            vmin=raw[column].min(),\n",
    "            vmax=raw[column].max(),\n",
    "            origin=\"lower\",\n",
    "            cmap=cmap,\n",
    "        )\n",
    "        axes[ii].set_aspect(\"auto\")\n",
    "    fig.subplots_adjust(right=1.0, hspace=0.05)\n",
    "\n",
    "\n",
    "ani = FuncAnimation(fig, animate, repeat_delay=600, interval=20, frames=len(iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save as animation parelllized with ffmpeg since the default matplotlib implemenation takes too long. Faster implemntation than matplotib from here: https://stackoverflow.com/a/31315362/3253411 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelize animation to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i : i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = multiprocessing.cpu_count()\n",
    "frames = [i for i in range(len(iterator))]\n",
    "\n",
    "# divide the frame equally\n",
    "i_length = math.ceil(len(frames) / (threads))\n",
    "frame_sets = list(chunks(frames, i_length))\n",
    "\n",
    "filenames = []\n",
    "for i in range(len(frame_sets)):\n",
    "    filenames.append(\"_temp_video_chunk_\" + str(i) + \".mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ani_to_mp4(frame_range, filename):\n",
    "    canvas_width, canvas_height = fig.canvas.get_width_height()\n",
    "\n",
    "    # Open an ffmpeg process\n",
    "    outf = os.path.join(\"results\", filename)\n",
    "    cmdstring = (\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",\n",
    "        \"-r\",\n",
    "        \"100\",  # fps\n",
    "        \"-s\",\n",
    "        f\"{canvas_width}x{canvas_height}\",  # size of image string\n",
    "        \"-pix_fmt\",\n",
    "        \"argb\",  # formats\n",
    "        \"-f\",\n",
    "        \"rawvideo\",\n",
    "        \"-i\",\n",
    "        \"-\",  # tell ffmpeg to expect raw video from the pipe\n",
    "        \"-vcodec\",\n",
    "        \"mpeg4\",\n",
    "        outf,\n",
    "    )  # output encoding\n",
    "    p = subprocess.Popen(cmdstring, stdin=subprocess.PIPE)\n",
    "\n",
    "    # Draw frames and write to the pipe\n",
    "    for frame in frame_range:\n",
    "        # draw the frame\n",
    "        animate(frame)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "        # extract the image as an ARGB string\n",
    "        string = fig.canvas.tostring_argb()\n",
    "\n",
    "        # write to pipe\n",
    "        p.stdin.write(string)\n",
    "\n",
    "    # Finish up\n",
    "    p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool() as pool:\n",
    "    pool.starmap(ani_to_mp4, zip(frame_sets, filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list = os.path.join(\"results\", \"filenames.txt\")\n",
    "with open(filename_list, \"w\") as textfile:\n",
    "    for filename in filenames:\n",
    "        textfile.write(\"file '\" + filename + \"'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmdstring = (\n",
    "    \"ffmpeg\",\n",
    "    \"-y\",\n",
    "    \"-f\",\n",
    "    \"concat\",\n",
    "    \"-safe\",\n",
    "    \"0\",\n",
    "    \"-i\",\n",
    "    filename_list,\n",
    "    \"-c\",\n",
    "    \"copy\",\n",
    "    os.path.join(\"results\", \"animation.mp4\"),\n",
    ")  # output encoding\n",
    "p = subprocess.Popen(cmdstring, stdin=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also show it inline but it takes quite long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
